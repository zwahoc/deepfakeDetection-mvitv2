{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14c136a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEEPFAKE DETECTION TRAINING — FREEZE → UNFREEZE FINE-TUNING\n",
      "================================================================================\n",
      "✓ Checkpoint path: C:\\Users\\Gan\\AI Testing\\checkpoint\n",
      "✓ Result path    : C:\\Users\\Gan\\AI Testing\\EfficientB3_result_graph\n",
      "\n",
      "System Info:\n",
      "  Device: cuda\n",
      "  GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "  VRAM: 6.00 GB\n",
      "\n",
      "Model Configuration:\n",
      "  Model         : efficientnet_b3\n",
      "  Image Size    : 300\n",
      "  Batch Size    : 16\n",
      "  Epochs        : 10\n",
      "  LR            : 0.0001\n",
      "  Freeze epochs : 1\n",
      "\n",
      "============================================================\n",
      "PREPARING DATASETS\n",
      "============================================================\n",
      "Using 20% of TRAIN, 100% of VAL\n",
      "  Loaded 14,000 fake, 14,000 real (total 28,000)\n",
      "  Loaded 19,641 fake, 19,787 real (total 39,428)\n",
      "\n",
      "Dataset Summary:\n",
      "  Train: 28,000 images\n",
      "  Val  : 39,428 images\n",
      "\n",
      "============================================================\n",
      "INITIALIZING MODEL\n",
      "============================================================\n",
      "Total params     : 11,485,226\n",
      "[Phase 1] Backbone FROZEN for 1 epoch(s). Trainable params: 788,994\n",
      "\n",
      "============================================================\n",
      "STARTING TRAINING\n",
      "============================================================\n",
      "\n",
      "==================================================\n",
      "EPOCH 1/10  [Phase 1: frozen]\n",
      "==================================================\n",
      "LR group(s): [1.200000000000002e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████| 1750/1750 [08:14<00:00,  3.54it/s, Loss=0.558, Acc=0.707]\n",
      "Validation: 100%|████████████████████████| 1233/1233 [08:52<00:00,  2.32it/s, Loss=0.016, Acc=0.760]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train Loss: 0.5579 | Train Acc: 0.707\n",
      "  Val   Loss: 0.5181 | Val Acc: 0.760 | F1: 0.743 | AUC: 0.846\n",
      "  Time: 1027.2s\n",
      "  ✓ Saved best model (F1: 0.743)\n",
      "\n",
      "[Phase 2] Backbone UNFROZEN for 9 epoch(s). Trainable params: 11,485,226\n",
      "\n",
      "==================================================\n",
      "EPOCH 2/10  [Phase 2: fine-tune]\n",
      "==================================================\n",
      "LR group(s): [1.1999999999999987e-06, 1.200000000000002e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████| 1750/1750 [10:43<00:00,  2.72it/s, Loss=0.440, Acc=0.793]\n",
      "Validation: 100%|████████████████████████| 1233/1233 [10:03<00:00,  2.04it/s, Loss=0.018, Acc=0.814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train Loss: 0.4405 | Train Acc: 0.793\n",
      "  Val   Loss: 0.5749 | Val Acc: 0.814 | F1: 0.798 | AUC: 0.907\n",
      "  Time: 1246.7s\n",
      "  ✓ Saved best model (F1: 0.798)\n",
      "\n",
      "==================================================\n",
      "EPOCH 3/10  [Phase 2: fine-tune]\n",
      "==================================================\n",
      "LR group(s): [1.2000286828724482e-06, 1.200028682872453e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████| 1750/1750 [10:46<00:00,  2.71it/s, Loss=0.340, Acc=0.850]\n",
      "Validation: 100%|████████████████████████| 1233/1233 [05:14<00:00,  3.92it/s, Loss=0.019, Acc=0.853]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train Loss: 0.3404 | Train Acc: 0.850\n",
      "  Val   Loss: 0.5932 | Val Acc: 0.853 | F1: 0.852 | AUC: 0.933\n",
      "  Time: 960.7s\n",
      "  ✓ Saved best model (F1: 0.852)\n",
      "\n",
      "==================================================\n",
      "EPOCH 4/10  [Phase 2: fine-tune]\n",
      "==================================================\n",
      "LR group(s): [1.2001147313755184e-06, 1.2001147313755198e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████| 1750/1750 [07:22<00:00,  3.96it/s, Loss=0.276, Acc=0.884]\n",
      "Validation: 100%|████████████████████████| 1233/1233 [04:42<00:00,  4.36it/s, Loss=0.015, Acc=0.860]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train Loss: 0.2760 | Train Acc: 0.884\n",
      "  Val   Loss: 0.4810 | Val Acc: 0.860 | F1: 0.849 | AUC: 0.950\n",
      "  Time: 725.1s\n",
      "\n",
      "==================================================\n",
      "EPOCH 5/10  [Phase 2: fine-tune]\n",
      "==================================================\n",
      "LR group(s): [1.2002581451664253e-06, 1.2002581451664267e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████| 1750/1750 [07:35<00:00,  3.84it/s, Loss=0.238, Acc=0.904]\n",
      "Validation: 100%|████████████████████████| 1233/1233 [04:42<00:00,  4.36it/s, Loss=0.015, Acc=0.892]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train Loss: 0.2379 | Train Acc: 0.904\n",
      "  Val   Loss: 0.4785 | Val Acc: 0.892 | F1: 0.891 | AUC: 0.961\n",
      "  Time: 738.6s\n",
      "  ✓ Saved best model (F1: 0.891)\n",
      "\n",
      "==================================================\n",
      "EPOCH 6/10  [Phase 2: fine-tune]\n",
      "==================================================\n",
      "LR group(s): [1.2004589236738452e-06, 1.2004589236738479e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████| 1750/1750 [07:18<00:00,  3.99it/s, Loss=0.213, Acc=0.915]\n",
      "Validation: 100%|████████████████████████| 1233/1233 [04:41<00:00,  4.38it/s, Loss=0.048, Acc=0.893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train Loss: 0.2125 | Train Acc: 0.915\n",
      "  Val   Loss: 1.5335 | Val Acc: 0.893 | F1: 0.887 | AUC: 0.967\n",
      "  Time: 720.5s\n",
      "\n",
      "==================================================\n",
      "EPOCH 7/10  [Phase 2: fine-tune]\n",
      "==================================================\n",
      "LR group(s): [1.2007170660979315e-06, 1.2007170660979349e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████| 1750/1750 [07:21<00:00,  3.97it/s, Loss=0.198, Acc=0.925]\n",
      "Validation: 100%|████████████████████████| 1233/1233 [04:41<00:00,  4.38it/s, Loss=0.015, Acc=0.902]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train Loss: 0.1983 | Train Acc: 0.925\n",
      "  Val   Loss: 0.4704 | Val Acc: 0.902 | F1: 0.898 | AUC: 0.971\n",
      "  Time: 722.9s\n",
      "  ✓ Saved best model (F1: 0.898)\n",
      "\n",
      "==================================================\n",
      "EPOCH 8/10  [Phase 2: fine-tune]\n",
      "==================================================\n",
      "LR group(s): [1.2010325714103084e-06, 1.2010325714103111e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████| 1750/1750 [07:20<00:00,  3.97it/s, Loss=0.181, Acc=0.932]\n",
      "Validation: 100%|████████████████████████| 1233/1233 [04:42<00:00,  4.37it/s, Loss=0.028, Acc=0.911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train Loss: 0.1805 | Train Acc: 0.932\n",
      "  Val   Loss: 0.8835 | Val Acc: 0.911 | F1: 0.907 | AUC: 0.976\n",
      "  Time: 722.8s\n",
      "  ✓ Saved best model (F1: 0.907)\n",
      "\n",
      "==================================================\n",
      "EPOCH 9/10  [Phase 2: fine-tune]\n",
      "==================================================\n",
      "LR group(s): [1.2014054383540908e-06, 1.2014054383540935e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████| 1750/1750 [07:21<00:00,  3.97it/s, Loss=0.177, Acc=0.933]\n",
      "Validation: 100%|████████████████████████| 1233/1233 [04:42<00:00,  4.36it/s, Loss=0.007, Acc=0.913]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train Loss: 0.1769 | Train Acc: 0.933\n",
      "  Val   Loss: 0.2262 | Val Acc: 0.913 | F1: 0.909 | AUC: 0.979\n",
      "  Time: 724.2s\n",
      "  ✓ Saved best model (F1: 0.909)\n",
      "\n",
      "==================================================\n",
      "EPOCH 10/10  [Phase 2: fine-tune]\n",
      "==================================================\n",
      "LR group(s): [1.2018356654438742e-06, 1.2018356654438817e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████| 1750/1750 [07:22<00:00,  3.96it/s, Loss=0.165, Acc=0.942]\n",
      "Validation: 100%|████████████████████████| 1233/1233 [04:43<00:00,  4.35it/s, Loss=0.023, Acc=0.906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train Loss: 0.1649 | Train Acc: 0.942\n",
      "  Val   Loss: 0.7472 | Val Acc: 0.906 | F1: 0.899 | AUC: 0.982\n",
      "  Time: 725.9s\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE - SAVING CURVES & FULL EVAL\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full Eval: 100%|████████████████████████████████████████████████| 1233/1233 [04:33<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full evaluation on best checkpoint:\n",
      "{'acc': 0.9133357005173988, 'prec': 0.9559865092748735, 'rec': 0.8658927753169391, 'f1': 0.9087120301354492, 'auc': 0.9787630943032425, 'prec_macro': 0.9171281099845113, 'rec_macro': 0.9131606697628816, 'f1_macro': 0.9131128044461193, 'prec_weight': 0.9169842191887216, 'rec_weight': 0.9133357005173988, 'f1_weight': 0.9131291003031083}\n",
      "\n",
      "✓ Best model saved to: C:\\Users\\Gan\\AI Testing\\checkpoint\n",
      "✓ Graphs & CSV saved to: C:\\Users\\Gan\\AI Testing\\EfficientB3_result_graph\n",
      "============================================================\n",
      "DONE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "EfficientNet-B3 Deepfake Detector\n",
    "- Freeze → Unfreeze fine-tuning\n",
    "- Per-epoch logging: Acc, Prec/Rec/F1 (macro & weighted), AUC\n",
    "- Saves graphs: loss/acc/F1/AUC curves\n",
    "- Saves per-phase, per-epoch: Confusion Matrix + ROC curve\n",
    "- Final full evaluation plots: Confusion, ROC, PR, Confidence hist, F1 vs Threshold\n",
    "\"\"\"\n",
    "\n",
    "# =========================\n",
    "# Imports & setup\n",
    "# =========================\n",
    "import os, random, time, json, itertools, warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, roc_curve, precision_recall_curve, classification_report,\n",
    "    precision_recall_fscore_support\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "class Config:\n",
    "    # Data\n",
    "    TRAIN_FAKE_PATH = r\"C:\\Users\\Gan\\AI\\DataSet\\Train\\Fake\"\n",
    "    TRAIN_REAL_PATH = r\"C:\\Users\\Gan\\AI\\DataSet\\Train\\Real\"\n",
    "    VAL_FAKE_PATH   = r\"C:\\Users\\Gan\\AI\\DataSet\\Validation\\Fake\"\n",
    "    VAL_REAL_PATH   = r\"C:\\Users\\Gan\\AI\\DataSet\\Validation\\Real\"\n",
    "    TEST_FAKE_PATH  = r\"C:\\Users\\Gan\\AI\\DataSet\\Test\\Fake\"\n",
    "    TEST_REAL_PATH  = r\"C:\\Users\\Gan\\AI\\DataSet\\Test\\Real\"\n",
    "\n",
    "    # Outputs (your required paths)\n",
    "    CHECKPOINT_PATH = r\"C:\\Users\\Gan\\AI Testing\\checkpoint\"\n",
    "    RESULT_GRAPH_PATH = r\"C:\\Users\\Gan\\AI Testing\\EfficientB3_result_graph\"\n",
    "\n",
    "    # Model / training\n",
    "    MODEL_NAME   = \"efficientnet_b3\"\n",
    "    IMAGE_SIZE   = 300\n",
    "    BATCH_SIZE   = 16\n",
    "    NUM_EPOCHS   = 10\n",
    "    LEARNING_RATE = 1e-4\n",
    "\n",
    "    # Freeze → unfreeze\n",
    "    FREEZE_BACKBONE_EPOCHS = 1\n",
    "    USE_DISCRIM_LR_AFTER_UNFREEZE = True\n",
    "    BACKBONE_LR_MULT = 0.3          # smaller LR for backbone\n",
    "    HEAD_LR_MULT     = 3.0          # larger LR for head\n",
    "\n",
    "    # Data usage\n",
    "    USE_FULL_DATA = False           # quick debug: 20% train\n",
    "    DATA_FRACTION = 0.2\n",
    "    VAL_FRACTION  = 1.0\n",
    "\n",
    "    # System\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    NUM_WORKERS = 0\n",
    "    PIN_MEMORY = True\n",
    "    USE_MIXED_PRECISION = True\n",
    "\n",
    "    # Early stopping (by F1)\n",
    "    EARLY_STOPPING_PATIENCE = 7\n",
    "\n",
    "# =========================\n",
    "# Dataset\n",
    "# =========================\n",
    "class DeepfakeDataset(Dataset):\n",
    "    def __init__(self, fake_path, real_path, transform=None, subset_fraction=1.0):\n",
    "        self.transform = transform\n",
    "        self.images, self.labels = [], []\n",
    "\n",
    "        def list_imgs(p):\n",
    "            if not os.path.exists(p): return []\n",
    "            return [os.path.join(p, f) for f in os.listdir(p)\n",
    "                    if f.lower().endswith(('.jpg','.jpeg','.png','.bmp','.webp','.tif','.tiff'))]\n",
    "\n",
    "        fake_files = list_imgs(fake_path)\n",
    "        real_files = list_imgs(real_path)\n",
    "\n",
    "        if subset_fraction < 1.0:\n",
    "            random.shuffle(fake_files); random.shuffle(real_files)\n",
    "            fake_files = fake_files[:int(len(fake_files)*subset_fraction)]\n",
    "            real_files = real_files[:int(len(real_files)*subset_fraction)]\n",
    "\n",
    "        # label: Real=0, Fake=1\n",
    "        self.images.extend(fake_files); self.labels.extend([1]*len(fake_files))\n",
    "        self.images.extend(real_files); self.labels.extend([0]*len(real_files))\n",
    "\n",
    "        combined = list(zip(self.images, self.labels))\n",
    "        random.shuffle(combined)\n",
    "        self.images, self.labels = zip(*combined) if combined else ([], [])\n",
    "\n",
    "        print(f\"  Loaded {len(fake_files):,} fake, {len(real_files):,} real (total {len(self.images):,})\")\n",
    "\n",
    "    def __len__(self): return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                image = Image.open(self.images[idx]).convert('RGB')\n",
    "                if self.transform: image = self.transform(image)\n",
    "                return image, self.labels[idx]\n",
    "            except Exception:\n",
    "                idx = (idx + 1) % len(self.images)\n",
    "        return torch.zeros(3, 300, 300), self.labels[idx]\n",
    "\n",
    "# =========================\n",
    "# Model\n",
    "# =========================\n",
    "class DeepfakeDetector(nn.Module):\n",
    "    def __init__(self, model_name=\"efficientnet_b3\", num_classes=2):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "\n",
    "        if model_name == \"efficientnet_b3\":\n",
    "            weights = models.EfficientNet_B3_Weights.IMAGENET1K_V1\n",
    "            self.backbone = models.efficientnet_b3(weights=weights)\n",
    "            in_features = self.backbone.classifier[1].in_features\n",
    "            self.backbone.classifier = nn.Sequential(\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(in_features, 512),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(512, num_classes)\n",
    "            )\n",
    "        elif model_name == \"efficientnet_b0\":\n",
    "            weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "            self.backbone = models.efficientnet_b0(weights=weights)\n",
    "            in_features = self.backbone.classifier[1].in_features\n",
    "            self.backbone.classifier = nn.Sequential(\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(in_features, 512),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(512, num_classes)\n",
    "            )\n",
    "        elif model_name == \"resnet50\":\n",
    "            weights = models.ResNet50_Weights.IMAGENET1K_V2\n",
    "            self.backbone = models.resnet50(weights=weights)\n",
    "            in_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(in_features, 512),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(512, num_classes)\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model: {model_name}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        if \"resnet\" in self.model_name:\n",
    "            x = self.backbone(x)\n",
    "            return self.classifier(x)\n",
    "        else:\n",
    "            return self.backbone(x)\n",
    "\n",
    "    def set_backbone_trainable(self, trainable: bool):\n",
    "        # freeze/unfreeze backbone features\n",
    "        if \"resnet\" in self.model_name:\n",
    "            modules = [self.backbone]\n",
    "        else:\n",
    "            modules = [self.backbone.features]\n",
    "        for m in modules:\n",
    "            for p in m.parameters():\n",
    "                p.requires_grad = trainable\n",
    "        # keep classifier trainable\n",
    "        if \"resnet\" in self.model_name:\n",
    "            for p in self.classifier.parameters(): p.requires_grad = True\n",
    "        else:\n",
    "            for p in self.backbone.classifier.parameters(): p.requires_grad = True\n",
    "\n",
    "def count_trainable_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# =========================\n",
    "# Optimizer & scheduler\n",
    "# =========================\n",
    "def make_optimizer_and_scheduler(model, cfg, steps_per_epoch, total_epochs, phase):\n",
    "    trainable = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "    if phase == 2 and cfg.USE_DISCRIM_LR_AFTER_UNFREEZE:\n",
    "        head_params, body_params = [], []\n",
    "        for n,p in model.named_parameters():\n",
    "            if not p.requires_grad: continue\n",
    "            if (\"classifier\" in n) or (\"fc\" in n):\n",
    "                head_params.append(p)\n",
    "            else:\n",
    "                body_params.append(p)\n",
    "        optimizer = optim.AdamW([\n",
    "            {\"params\": body_params, \"lr\": cfg.LEARNING_RATE * cfg.BACKBONE_LR_MULT},\n",
    "            {\"params\": head_params, \"lr\": cfg.LEARNING_RATE * cfg.HEAD_LR_MULT},\n",
    "        ], weight_decay=1e-4)\n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=[cfg.LEARNING_RATE * cfg.BACKBONE_LR_MULT,\n",
    "                    cfg.LEARNING_RATE * cfg.HEAD_LR_MULT],\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=total_epochs,\n",
    "            pct_start=0.1\n",
    "        )\n",
    "    else:\n",
    "        optimizer = optim.AdamW(trainable, lr=cfg.LEARNING_RATE, weight_decay=1e-4)\n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=cfg.LEARNING_RATE * 3,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=total_epochs,\n",
    "            pct_start=0.1\n",
    "        )\n",
    "    return optimizer, scheduler\n",
    "\n",
    "# =========================\n",
    "# Train / Validate\n",
    "# =========================\n",
    "def train_epoch(model, loader, criterion, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    pbar = tqdm(loader, desc=\"Training\", ncols=100)\n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with autocast(enabled=scaler is not None):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix({\"Loss\": f\"{running_loss/len(loader):.3f}\",\n",
    "                          \"Acc\": f\"{correct/max(1,total):.3f}\"})\n",
    "    return running_loss / max(1,len(loader)), correct / max(1,total)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_epoch(model, loader, criterion, device, desc=\"Validation\"):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "\n",
    "    pbar = tqdm(loader, desc=desc, ncols=100)\n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        probs = F.softmax(outputs, dim=1)[:, 1]  # P(Fake)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probs .extend(probs.cpu().numpy())\n",
    "\n",
    "        acc_live = accuracy_score(all_labels, all_preds) if len(all_labels)>0 else 0.0\n",
    "        pbar.set_postfix({\"Loss\": f\"{running_loss/max(1,len(all_labels)):.3f}\",\n",
    "                          \"Acc\": f\"{acc_live:.3f}\"})\n",
    "\n",
    "    # Basic (binary)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, zero_division=0)\n",
    "    recall    = recall_score(all_labels, all_preds, zero_division=0)\n",
    "    f1        = f1_score(all_labels, all_preds, zero_division=0)\n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_probs)\n",
    "    except:\n",
    "        auc = 0.5\n",
    "\n",
    "    # Macro & Weighted\n",
    "    prec_macro, rec_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average=\"macro\", zero_division=0)\n",
    "    prec_weight, rec_weight, f1_weight, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    return {\n",
    "        \"loss\": running_loss / max(1,len(loader)),\n",
    "        \"acc\": accuracy, \"prec\": precision, \"rec\": recall, \"f1\": f1, \"auc\": auc,\n",
    "        \"prec_macro\": prec_macro, \"rec_macro\": rec_macro, \"f1_macro\": f1_macro,\n",
    "        \"prec_weight\": prec_weight, \"rec_weight\": rec_weight, \"f1_weight\": f1_weight,\n",
    "        \"labels\": np.array(all_labels), \"preds\": np.array(all_preds), \"probs\": np.array(all_probs)\n",
    "    }\n",
    "\n",
    "# =========================\n",
    "# Plot helpers\n",
    "# =========================\n",
    "def plot_lines(x, ys, labels, title, ylabel, out_path):\n",
    "    plt.figure(figsize=(8,5))\n",
    "    for y, lab in zip(ys, labels):\n",
    "        plt.plot(x, y, marker=\"o\", label=lab)\n",
    "    plt.title(title); plt.xlabel(\"Epoch\"); plt.ylabel(ylabel)\n",
    "    plt.grid(True, linestyle=\"--\", linewidth=0.5); plt.legend()\n",
    "    plt.savefig(out_path, dpi=160, bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "def save_confusion_and_roc(y_true, y_prob, phase_label, epoch, out_dir, threshold=0.5):\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "    fig, ax = plt.subplots(figsize=(6,5))\n",
    "    im = ax.imshow(cm, cmap=\"Blues\")\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
    "    ax.set_xticklabels([\"Real\",\"Fake\"]); ax.set_yticklabels([\"Real\",\"Fake\"])\n",
    "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"Actual\")\n",
    "    ax.set_title(f\"Confusion Matrix — {phase_label} (Epoch {epoch})\")\n",
    "    thresh = cm.max()/2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    cm_path = os.path.join(out_dir, f\"confusion_{phase_label.lower()}_epoch{epoch}.png\")\n",
    "    plt.savefig(cm_path, dpi=160, bbox_inches=\"tight\"); plt.close(fig)\n",
    "\n",
    "    # ROC\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    auc_val = roc_auc_score(y_true, y_prob)\n",
    "    fig = plt.figure(figsize=(6,5))\n",
    "    plt.plot(fpr, tpr, lw=2, label=f\"AUC = {auc_val:.3f}\")\n",
    "    plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC Curve — {phase_label} (Epoch {epoch})\"); plt.legend(loc=\"lower right\")\n",
    "    roc_path = os.path.join(out_dir, f\"roc_{phase_label.lower()}_epoch{epoch}.png\")\n",
    "    plt.savefig(roc_path, dpi=160, bbox_inches=\"tight\"); plt.close(fig)\n",
    "\n",
    "    return cm_path, roc_path, float(auc_val)\n",
    "\n",
    "# =========================\n",
    "# Metrics logger\n",
    "# =========================\n",
    "class MetricsLogger:\n",
    "    def __init__(self, out_dir):\n",
    "        self.out_dir = out_dir\n",
    "        self.rows = []\n",
    "\n",
    "    def log(self, epoch, phase, stats):\n",
    "        r = dict(epoch=epoch, phase=phase)\n",
    "        r.update({\n",
    "            \"train_loss\": stats.get(\"train_loss\", np.nan),\n",
    "            \"train_acc\":  stats.get(\"train_acc\",  np.nan),\n",
    "            \"val_loss\":   stats[\"val_loss\"],\n",
    "            \"val_acc\":    stats[\"val_acc\"],\n",
    "            \"val_prec\":   stats[\"val_prec\"],\n",
    "            \"val_rec\":    stats[\"val_rec\"],\n",
    "            \"val_f1\":     stats[\"val_f1\"],\n",
    "            \"val_auc\":    stats[\"val_auc\"],\n",
    "            \"val_prec_macro\":   stats[\"val_prec_macro\"],\n",
    "            \"val_rec_macro\":    stats[\"val_rec_macro\"],\n",
    "            \"val_f1_macro\":     stats[\"val_f1_macro\"],\n",
    "            \"val_prec_weight\":  stats[\"val_prec_weight\"],\n",
    "            \"val_rec_weight\":   stats[\"val_rec_weight\"],\n",
    "            \"val_f1_weight\":    stats[\"val_f1_weight\"],\n",
    "        })\n",
    "        self.rows.append(r)\n",
    "\n",
    "    def to_df(self):\n",
    "        return pd.DataFrame(self.rows)\n",
    "\n",
    "    def save_csv(self, fname=\"metrics_per_epoch.csv\"):\n",
    "        p = os.path.join(self.out_dir, fname)\n",
    "        self.to_df().to_csv(p, index=False)\n",
    "        return p\n",
    "\n",
    "# =========================\n",
    "# Full evaluation (final)\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def evaluate_full(model, loader, device, out_dir, class_names=(\"Real\",\"Fake\"), threshold=0.5):\n",
    "    model.eval()\n",
    "    y_true, y_prob = [], []\n",
    "\n",
    "    for images, labels in tqdm(loader, desc=\"Full Eval\", ncols=100):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        logits = model(images)\n",
    "        probs = F.softmax(logits, dim=1)[:,1]\n",
    "        y_true.extend(labels.cpu().numpy().tolist())\n",
    "        y_prob.extend(probs.cpu().numpy().tolist())\n",
    "\n",
    "    y_true = np.array(y_true); y_prob = np.array(y_prob)\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    # Save raw arrays\n",
    "    np.save(os.path.join(out_dir, \"y_true.npy\"), y_true)\n",
    "    np.save(os.path.join(out_dir, \"y_pred.npy\"), y_pred)\n",
    "    np.save(os.path.join(out_dir, \"y_prob_fake.npy\"), y_prob)\n",
    "\n",
    "    # Metrics\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    auc  = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "    # Macro & weighted\n",
    "    prec_macro, rec_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    prec_weight, rec_weight, f1_weight, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    # Report\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names, zero_division=0)\n",
    "    with open(os.path.join(out_dir, \"classification_report.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(report + \"\\n\")\n",
    "        f.write(f\"\\nOverall:\\nacc={acc:.4f}  prec={prec:.4f}  rec={rec:.4f}  f1={f1:.4f}  auc={auc:.4f}\\n\")\n",
    "        f.write(f\"macro: prec={prec_macro:.4f} rec={rec_macro:.4f} f1={f1_macro:.4f}\\n\")\n",
    "        f.write(f\"weighted: prec={prec_weight:.4f} rec={rec_weight:.4f} f1={f1_weight:.4f}\\n\")\n",
    "\n",
    "    # Plots\n",
    "    save_confusion_and_roc(y_true, y_prob, \"Final\", \"best\", out_dir, threshold=threshold)\n",
    "\n",
    "    # PR curve\n",
    "    ps, rs, _ = precision_recall_curve(y_true, y_prob)\n",
    "    fig = plt.figure(figsize=(6,5))\n",
    "    plt.plot(rs, ps, lw=2)\n",
    "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Precision–Recall Curve (Final)\")\n",
    "    plt.grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "    plt.savefig(os.path.join(out_dir, \"pr_curve.png\"), dpi=160, bbox_inches=\"tight\"); plt.close(fig)\n",
    "\n",
    "    # Confidence histogram\n",
    "    fig = plt.figure(figsize=(8,4))\n",
    "    plt.hist([p for p,t in zip(y_prob, y_true) if t==0], bins=30, alpha=0.6, label=\"P(Fake) | Real\")\n",
    "    plt.hist([p for p,t in zip(y_prob, y_true) if t==1], bins=30, alpha=0.6, label=\"P(Fake) | Fake\")\n",
    "    plt.axvline(threshold, color=\"k\", linestyle=\"--\", label=f\"Threshold={threshold:.2f}\")\n",
    "    plt.xlabel(\"P(Fake)\"); plt.ylabel(\"Count\"); plt.title(\"Confidence Histogram (Final)\"); plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "    plt.savefig(os.path.join(out_dir, \"confidence_hist.png\"), dpi=160, bbox_inches=\"tight\"); plt.close(fig)\n",
    "\n",
    "    # F1 vs threshold\n",
    "    ths = np.linspace(0.05, 0.95, 19)\n",
    "    f1s = []\n",
    "    for th in ths:\n",
    "        preds = (y_prob >= th).astype(int)\n",
    "        f1s.append(f1_score(y_true, preds, zero_division=0))\n",
    "    fig = plt.figure(figsize=(6,5))\n",
    "    plt.plot(ths, f1s, marker=\"o\")\n",
    "    plt.xlabel(\"Threshold on P(Fake)\"); plt.ylabel(\"F1\"); plt.title(\"F1 vs Threshold (Final)\")\n",
    "    plt.grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "    plt.savefig(os.path.join(out_dir, \"f1_vs_threshold.png\"), dpi=160, bbox_inches=\"tight\"); plt.close(fig)\n",
    "\n",
    "    return {\n",
    "        \"acc\":acc, \"prec\":prec, \"rec\":rec, \"f1\":f1, \"auc\":auc,\n",
    "        \"prec_macro\":prec_macro, \"rec_macro\":rec_macro, \"f1_macro\":f1_macro,\n",
    "        \"prec_weight\":prec_weight, \"rec_weight\":rec_weight, \"f1_weight\":f1_weight\n",
    "    }\n",
    "\n",
    "# =========================\n",
    "# Main\n",
    "# =========================\n",
    "def main():\n",
    "    cfg = Config()\n",
    "    Path(cfg.CHECKPOINT_PATH).mkdir(parents=True, exist_ok=True)\n",
    "    Path(cfg.RESULT_GRAPH_PATH).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(\"DEEPFAKE DETECTION TRAINING — FREEZE → UNFREEZE FINE-TUNING\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"✓ Checkpoint path: {cfg.CHECKPOINT_PATH}\")\n",
    "    print(f\"✓ Result path    : {cfg.RESULT_GRAPH_PATH}\")\n",
    "    print(\"\\nSystem Info:\")\n",
    "    print(\"  Device:\", cfg.DEVICE)\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"  GPU:\", torch.cuda.get_device_name(0))\n",
    "        print(f\"  VRAM: {torch.cuda.get_device_properties(0).total_memory/1024**3:.2f} GB\")\n",
    "\n",
    "    random.seed(42); np.random.seed(42); torch.manual_seed(42)\n",
    "    if torch.cuda.is_available(): torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    print(\"\\nModel Configuration:\")\n",
    "    print(f\"  Model         : {cfg.MODEL_NAME}\")\n",
    "    print(f\"  Image Size    : {cfg.IMAGE_SIZE}\")\n",
    "    print(f\"  Batch Size    : {cfg.BATCH_SIZE}\")\n",
    "    print(f\"  Epochs        : {cfg.NUM_EPOCHS}\")\n",
    "    print(f\"  LR            : {cfg.LEARNING_RATE}\")\n",
    "    print(f\"  Freeze epochs : {cfg.FREEZE_BACKBONE_EPOCHS}\")\n",
    "\n",
    "    # Transforms\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.Resize((cfg.IMAGE_SIZE, cfg.IMAGE_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.ColorJitter(0.2,0.2,0.2,0.05),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "    ])\n",
    "    eval_tf = transforms.Compose([\n",
    "        transforms.Resize((cfg.IMAGE_SIZE, cfg.IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "    ])\n",
    "\n",
    "    frac_train = 1.0 if cfg.USE_FULL_DATA else cfg.DATA_FRACTION\n",
    "    frac_val   = cfg.VAL_FRACTION\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PREPARING DATASETS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Using {frac_train*100:.0f}% of TRAIN, {frac_val*100:.0f}% of VAL\")\n",
    "\n",
    "    train_dataset = DeepfakeDataset(cfg.TRAIN_FAKE_PATH, cfg.TRAIN_REAL_PATH, transform=train_tf, subset_fraction=frac_train)\n",
    "    val_dataset   = DeepfakeDataset(cfg.VAL_FAKE_PATH,   cfg.VAL_REAL_PATH,   transform=eval_tf,  subset_fraction=frac_val)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=cfg.BATCH_SIZE, shuffle=True,\n",
    "                              num_workers=cfg.NUM_WORKERS, pin_memory=cfg.PIN_MEMORY, drop_last=True)\n",
    "    val_loader   = DataLoader(val_dataset,   batch_size=cfg.BATCH_SIZE*2, shuffle=False,\n",
    "                              num_workers=cfg.NUM_WORKERS, pin_memory=cfg.PIN_MEMORY)\n",
    "\n",
    "    print(\"\\nDataset Summary:\")\n",
    "    print(f\"  Train: {len(train_dataset):,} images\")\n",
    "    print(f\"  Val  : {len(val_dataset):,} images\")\n",
    "\n",
    "    # Model\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"INITIALIZING MODEL\")\n",
    "    print(\"=\"*60)\n",
    "    model = DeepfakeDetector(model_name=cfg.MODEL_NAME).to(cfg.DEVICE)\n",
    "    print(f\"Total params     : {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "    # Phase split\n",
    "    phase1_epochs = min(cfg.FREEZE_BACKBONE_EPOCHS, cfg.NUM_EPOCHS)\n",
    "    phase2_epochs = cfg.NUM_EPOCHS - phase1_epochs\n",
    "\n",
    "    # Phase 1: freeze\n",
    "    if phase1_epochs > 0:\n",
    "        model.set_backbone_trainable(False)\n",
    "        print(f\"[Phase 1] Backbone FROZEN for {phase1_epochs} epoch(s). Trainable params: {count_trainable_params(model):,}\")\n",
    "    else:\n",
    "        print(\"[Phase 1] No freezing (skip).\")\n",
    "\n",
    "    scaler   = GradScaler() if cfg.USE_MIXED_PRECISION and cfg.DEVICE.type == \"cuda\" else None\n",
    "    criterion= nn.CrossEntropyLoss()\n",
    "    p1_epochs= phase1_epochs if phase1_epochs > 0 else cfg.NUM_EPOCHS\n",
    "    optimizer, scheduler = make_optimizer_and_scheduler(model, cfg, len(train_loader), p1_epochs, phase=1)\n",
    "    logger = MetricsLogger(cfg.RESULT_GRAPH_PATH)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STARTING TRAINING\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    best_val_f1, patience, epoch = 0.0, 0, 0\n",
    "    epochs_axis, train_losses, val_losses, val_accs, val_f1s, val_aucs = [], [], [], [], [], []\n",
    "\n",
    "    # ---------- Phase 1 loop ----------\n",
    "    for e in range(p1_epochs):\n",
    "        epoch += 1\n",
    "        print(f\"\\n{'='*50}\\nEPOCH {epoch}/{cfg.NUM_EPOCHS}  [Phase 1: frozen]\\n{'='*50}\")\n",
    "        print(f\"LR group(s): {[pg['lr'] for pg in optimizer.param_groups]}\")\n",
    "\n",
    "        t0 = time.time()\n",
    "        tr_loss, tr_acc = train_epoch(model, train_loader, criterion, optimizer, scaler, cfg.DEVICE)\n",
    "        scheduler.step()\n",
    "        val_stats = validate_epoch(model, val_loader, criterion, cfg.DEVICE, desc=\"Validation\")\n",
    "        dt = time.time()-t0\n",
    "\n",
    "        print(\"\\nResults:\")\n",
    "        print(f\"  Train Loss: {tr_loss:.4f} | Train Acc: {tr_acc:.3f}\")\n",
    "        print(f\"  Val   Loss: {val_stats['loss']:.4f} | Val Acc: {val_stats['acc']:.3f} | \"\n",
    "              f\"F1: {val_stats['f1']:.3f} | AUC: {val_stats['auc']:.3f}\")\n",
    "        print(f\"  Time: {dt:.1f}s\")\n",
    "\n",
    "        # Log series\n",
    "        epochs_axis.append(epoch)\n",
    "        train_losses.append(tr_loss); val_losses.append(val_stats[\"loss\"])\n",
    "        val_accs.append(val_stats[\"acc\"]); val_f1s.append(val_stats[\"f1\"]); val_aucs.append(val_stats[\"auc\"])\n",
    "\n",
    "        # Save per-phase confusion & ROC\n",
    "        save_confusion_and_roc(val_stats[\"labels\"], val_stats[\"probs\"], \"Phase1\", epoch, cfg.RESULT_GRAPH_PATH, threshold=0.5)\n",
    "\n",
    "        # Save best by F1\n",
    "        if val_stats[\"f1\"] > best_val_f1:\n",
    "            best_val_f1, patience = val_stats[\"f1\"], 0\n",
    "            torch.save({\"epoch\": epoch, \"model_state_dict\": model.state_dict(),\n",
    "                        \"val_acc\": val_stats[\"acc\"], \"val_f1\": val_stats[\"f1\"]},\n",
    "                       os.path.join(cfg.CHECKPOINT_PATH, f\"best_{cfg.MODEL_NAME}.pth\"))\n",
    "            print(f\"  ✓ Saved best model (F1: {val_stats['f1']:.3f})\")\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= cfg.EARLY_STOPPING_PATIENCE:\n",
    "                print(f\"\\n⚠ Early stopping at epoch {epoch} (Phase 1)\")\n",
    "                break\n",
    "\n",
    "        # log row\n",
    "        logger.log(epoch, \"phase1\", {\n",
    "            \"train_loss\": tr_loss, \"train_acc\": tr_acc,\n",
    "            \"val_loss\": val_stats[\"loss\"], \"val_acc\": val_stats[\"acc\"],\n",
    "            \"val_prec\": val_stats[\"prec\"], \"val_rec\": val_stats[\"rec\"], \"val_f1\": val_stats[\"f1\"],\n",
    "            \"val_auc\": val_stats[\"auc\"],\n",
    "            \"val_prec_macro\": val_stats[\"prec_macro\"], \"val_rec_macro\": val_stats[\"rec_macro\"], \"val_f1_macro\": val_stats[\"f1_macro\"],\n",
    "            \"val_prec_weight\": val_stats[\"prec_weight\"], \"val_rec_weight\": val_stats[\"rec_weight\"], \"val_f1_weight\": val_stats[\"f1_weight\"],\n",
    "        })\n",
    "\n",
    "    # ---------- Phase 2 loop ----------\n",
    "    if phase2_epochs > 0 and patience < cfg.EARLY_STOPPING_PATIENCE:\n",
    "        model.set_backbone_trainable(True)\n",
    "        print(f\"\\n[Phase 2] Backbone UNFROZEN for {phase2_epochs} epoch(s). Trainable params: {count_trainable_params(model):,}\")\n",
    "        optimizer, scheduler = make_optimizer_and_scheduler(model, cfg, len(train_loader), phase2_epochs, phase=2)\n",
    "        patience = 0\n",
    "\n",
    "        for e in range(phase2_epochs):\n",
    "            epoch += 1\n",
    "            print(f\"\\n{'='*50}\\nEPOCH {epoch}/{cfg.NUM_EPOCHS}  [Phase 2: fine-tune]\\n{'='*50}\")\n",
    "            print(f\"LR group(s): {[pg['lr'] for pg in optimizer.param_groups]}\")\n",
    "\n",
    "            t0 = time.time()\n",
    "            tr_loss, tr_acc = train_epoch(model, train_loader, criterion, optimizer, scaler, cfg.DEVICE)\n",
    "            scheduler.step()\n",
    "            val_stats = validate_epoch(model, val_loader, criterion, cfg.DEVICE, desc=\"Validation\")\n",
    "            dt = time.time()-t0\n",
    "\n",
    "            print(\"\\nResults:\")\n",
    "            print(f\"  Train Loss: {tr_loss:.4f} | Train Acc: {tr_acc:.3f}\")\n",
    "            print(f\"  Val   Loss: {val_stats['loss']:.4f} | Val Acc: {val_stats['acc']:.3f} | \"\n",
    "                  f\"F1: {val_stats['f1']:.3f} | AUC: {val_stats['auc']:.3f}\")\n",
    "            print(f\"  Time: {dt:.1f}s\")\n",
    "\n",
    "            # series\n",
    "            epochs_axis.append(epoch)\n",
    "            train_losses.append(tr_loss); val_losses.append(val_stats[\"loss\"])\n",
    "            val_accs.append(val_stats[\"acc\"]); val_f1s.append(val_stats[\"f1\"]); val_aucs.append(val_stats[\"auc\"])\n",
    "\n",
    "            # per-epoch confusion & ROC\n",
    "            save_confusion_and_roc(val_stats[\"labels\"], val_stats[\"probs\"], \"Phase2\", epoch, cfg.RESULT_GRAPH_PATH, threshold=0.5)\n",
    "\n",
    "            # save best by F1\n",
    "            if val_stats[\"f1\"] > best_val_f1:\n",
    "                best_val_f1, patience = val_stats[\"f1\"], 0\n",
    "                torch.save({\"epoch\": epoch, \"model_state_dict\": model.state_dict(),\n",
    "                            \"val_acc\": val_stats[\"acc\"], \"val_f1\": val_stats[\"f1\"]},\n",
    "                           os.path.join(cfg.CHECKPOINT_PATH, f\"best_{cfg.MODEL_NAME}.pth\"))\n",
    "                print(f\"  ✓ Saved best model (F1: {val_stats['f1']:.3f})\")\n",
    "            else:\n",
    "                patience += 1\n",
    "                if patience >= cfg.EARLY_STOPPING_PATIENCE:\n",
    "                    print(f\"\\n⚠ Early stopping at epoch {epoch} (Phase 2)\")\n",
    "                    break\n",
    "\n",
    "            # log\n",
    "            logger.log(epoch, \"phase2\", {\n",
    "                \"train_loss\": tr_loss, \"train_acc\": tr_acc,\n",
    "                \"val_loss\": val_stats[\"loss\"], \"val_acc\": val_stats[\"acc\"],\n",
    "                \"val_prec\": val_stats[\"prec\"], \"val_rec\": val_stats[\"rec\"], \"val_f1\": val_stats[\"f1\"],\n",
    "                \"val_auc\": val_stats[\"auc\"],\n",
    "                \"val_prec_macro\": val_stats[\"prec_macro\"], \"val_rec_macro\": val_stats[\"rec_macro\"], \"val_f1_macro\": val_stats[\"f1_macro\"],\n",
    "                \"val_prec_weight\": val_stats[\"prec_weight\"], \"val_rec_weight\": val_stats[\"rec_weight\"], \"val_f1_weight\": val_stats[\"f1_weight\"],\n",
    "            })\n",
    "\n",
    "    # ---------- Save curves & CSV ----------\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRAINING COMPLETE - SAVING CURVES & FULL EVAL\")\n",
    "    print(\"=\"*60)\n",
    "    csv_path = logger.save_csv()\n",
    "\n",
    "    plot_lines(epochs_axis, [train_losses, val_losses], [\"Train Loss\",\"Val Loss\"],\n",
    "               \"Training vs Validation Loss\", \"Loss\",\n",
    "               os.path.join(cfg.RESULT_GRAPH_PATH, \"loss_curve.png\"))\n",
    "    plot_lines(epochs_axis, [val_accs], [\"Val Accuracy\"],\n",
    "               \"Validation Accuracy\", \"Accuracy\",\n",
    "               os.path.join(cfg.RESULT_GRAPH_PATH, \"accuracy_curve.png\"))\n",
    "    plot_lines(epochs_axis, [val_f1s], [\"Val F1\"],\n",
    "               \"Validation F1\", \"F1\",\n",
    "               os.path.join(cfg.RESULT_GRAPH_PATH, \"f1_curve.png\"))\n",
    "    plot_lines(epochs_axis, [val_aucs], [\"Val AUC\"],\n",
    "               \"Validation AUC (ROC)\", \"AUC\",\n",
    "               os.path.join(cfg.RESULT_GRAPH_PATH, \"auc_curve.png\"))\n",
    "\n",
    "    # ---------- Load best & full evaluation ----------\n",
    "    best_ckpt = os.path.join(cfg.CHECKPOINT_PATH, f\"best_{cfg.MODEL_NAME}.pth\")\n",
    "    if os.path.isfile(best_ckpt):\n",
    "        state = torch.load(best_ckpt, map_location=cfg.DEVICE)\n",
    "        sd = state.get(\"model_state_dict\", state.get(\"model_state\"))\n",
    "        model.load_state_dict(sd)\n",
    "        final_scores = evaluate_full(model, val_loader, cfg.DEVICE, cfg.RESULT_GRAPH_PATH, class_names=(\"Real\",\"Fake\"), threshold=0.5)\n",
    "        print(\"\\nFull evaluation on best checkpoint:\")\n",
    "        print(final_scores)\n",
    "    else:\n",
    "        print(f\"\\n⚠ Best checkpoint not found at {best_ckpt}; skipping full evaluation.\")\n",
    "\n",
    "    print(f\"\\n✓ Best model saved to: {cfg.CHECKPOINT_PATH}\")\n",
    "    print(f\"✓ Graphs & CSV saved to: {cfg.RESULT_GRAPH_PATH}\")\n",
    "    print(\"=\"*60); print(\"DONE\"); print(\"=\"*60)\n",
    "\n",
    "# =========================\n",
    "# Single image test (optional)\n",
    "# =========================\n",
    "def single_image_test(img_path, threshold=0.5):\n",
    "    cfg = Config()\n",
    "    device = cfg.DEVICE\n",
    "    model = DeepfakeDetector(model_name=cfg.MODEL_NAME).to(device)\n",
    "    ckpt_path = os.path.join(cfg.CHECKPOINT_PATH, f\"best_{cfg.MODEL_NAME}.pth\")\n",
    "    if not os.path.isfile(ckpt_path):\n",
    "        raise FileNotFoundError(f\"Best checkpoint not found at: {ckpt_path}\")\n",
    "    state = torch.load(ckpt_path, map_location=device)\n",
    "    sd = state.get(\"model_state_dict\", state.get(\"model_state\"))\n",
    "    model.load_state_dict(sd); model.eval()\n",
    "\n",
    "    tf = transforms.Compose([\n",
    "        transforms.Resize((cfg.IMAGE_SIZE, cfg.IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "    ])\n",
    "\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    x = tf(img).unsqueeze(0).to(device)\n",
    "\n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        with autocast(enabled=cfg.USE_MIXED_PRECISION and device.type==\"cuda\"):\n",
    "            logits = model(x)\n",
    "            probs = torch.softmax(logits, dim=1).squeeze(0).cpu().numpy()\n",
    "    dt_ms = (time.time()-t0)*1000.0\n",
    "\n",
    "    p_real, p_fake = float(probs[0]), float(probs[1])\n",
    "    pred = \"Fake\" if p_fake >= threshold else \"Real\"\n",
    "\n",
    "    print(\"\\n--- Single-image prediction ---\")\n",
    "    print(f\"Path       : {img_path}\")\n",
    "    print(f\"Pred label : {pred}  (threshold={threshold:.2f})\")\n",
    "    print(f\"Prob(Fake) : {p_fake:.4f}\")\n",
    "    print(f\"Prob(Real) : {p_real:.4f}\")\n",
    "    print(f\"Latency    : {dt_ms:.1f} ms\")\n",
    "\n",
    "    plt.figure(figsize=(5,5)); plt.imshow(img); plt.axis(\"off\")\n",
    "    plt.title(f\"{pred}  |  P(Fake)={p_fake:.3f}\")\n",
    "    plt.show()\n",
    "    return pred, p_fake\n",
    "\n",
    "# =========================\n",
    "# Run\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    # Example:\n",
    "    # single_image_test(r\"C:\\Users\\Gan\\Pictures\\example.jpg\", threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfake_video_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
